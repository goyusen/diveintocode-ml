{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "australian-chester",
   "metadata": {},
   "source": [
    "# sprint14 ディープラーニング フレームワーク2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-leadership",
   "metadata": {},
   "source": [
    "## 1.このSprintについて\n",
    "\n",
    "**Sprintの目的**\n",
    "\n",
    "- フレームワークのコードを読めるようにする\n",
    "- フレームワークを習得し続けられるようになる\n",
    "- 理論を知っている範囲をフレームワークで動かす\n",
    "\n",
    "**どのように学ぶか**\n",
    "\n",
    "前半はTensorFlowのExampleを動かします。後半ではKerasのコードを書いていきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-desert",
   "metadata": {},
   "source": [
    "## 2.公式Example\n",
    "\n",
    "深層学習フレームワークには公式に様々なモデルのExampleコードが公開されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-gates",
   "metadata": {},
   "source": [
    "## 【問題1】公式チュートリアルモデルを分担して実行\n",
    "TensorFLowの公式チュートリアルモデルを分担して実行してください。\n",
    "\n",
    "\n",
    "以下の中から1人ひとつ選び実行し、その結果を簡単に発表してください。\n",
    "\n",
    "\n",
    "[models/tutorials at master · tensorflow/models](https://www.tensorflow.org/tutorials/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-brother",
   "metadata": {},
   "source": [
    "**選んだチュートリアルモデル：[RNN によるテキスト生成](https://www.tensorflow.org/tutorials/text/text_generation)**\n",
    "\n",
    "**RNNとは**\n",
    "時系列を扱うニューラルネットの一種。自然言語などの処理に使われる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-retreat",
   "metadata": {},
   "source": [
    "> このチュートリアルでは、文字ベースの RNN を使ってテキストを生成する方法を示します。ここでは、Andrej Karpathy の [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) からのシェイクスピア作品のデータセットを使います。このデータからの文字列（\"Shakespear\"）を入力にして、文字列中の次の文字（\"e\"）を予測するモデルを訓練します。このモデルを繰り返し呼び出すことで、より長い文字列を生成することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-milton",
   "metadata": {},
   "source": [
    "このチュートリアルには、tf.keras と eager execution を使ったコードが含まれています。下記は、このチュートリアルのモデルを 30 エポック訓練したものに対して、文字列 \"Q\" を初期値とした場合の出力例です。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "integrated-hollywood",
   "metadata": {},
   "source": [
    "QUEENE:\n",
    "I had thought thou hadst a Roman; for the oracle,\n",
    "Thus by All bids the man against the word,\n",
    "Which are so weak of care, by old care done;\n",
    "Your children were in your holy love,\n",
    "And the precipitation through the bleeding throne.\n",
    "\n",
    "BISHOP OF ELY:\n",
    "Marry, and will, my lord, to weep in such a one were prettiest;\n",
    "Yet now I was adopted heir\n",
    "Of the world's lamentable day,\n",
    "To watch the next way with his father with his face?\n",
    "\n",
    "ESCALUS:\n",
    "The cause why then we are all resolved more sons.\n",
    "\n",
    "VOLUMNIA:\n",
    "O, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, it is no sin it should be dead,\n",
    "And love and pale as any will to that word.\n",
    "\n",
    "QUEEN ELIZABETH:\n",
    "But how long have I heard the soul for this world,\n",
    "And show his hands of life be proved to stand.\n",
    "\n",
    "PETRUCHIO:\n",
    "I say he look'd on, if I must be content\n",
    "To stay him from the fatal of our country's bliss.\n",
    "His lordship pluck'd from this sentence then for prey,\n",
    "And then let us twain, being the moon,\n",
    "were she such a case as fills m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-diagram",
   "metadata": {},
   "source": [
    "いくつかは文法にあったものがある一方で、ほとんどは意味をなしていません。このモデルは、単語の意味を学習していませんが、次のことを考えてみてください。\n",
    "\n",
    "- このモデルは文字ベースです。訓練が始まった時に、モデルは英語の単語のスペルも知りませんし、単語がテキストの単位であることも知らないのです。\n",
    "\n",
    "- 出力の構造は戯曲に似ています。だいたいのばあい、データセットとおなじ大文字で書かれた話し手の名前で始まっています。\n",
    "\n",
    "- 以下に示すように、モデルはテキストの小さなバッチ（各100文字）で訓練されていますが、一貫した構造のより長いテキストのシーケンスを生成できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-schema",
   "metadata": {},
   "source": [
    "## 設定\n",
    "### TensorFlow 等のライブラリインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "basic-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# インポート\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-moderator",
   "metadata": {},
   "source": [
    "### シェイクスピアデータセットのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "second-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-arcade",
   "metadata": {},
   "source": [
    "### データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "widespread-headquarters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "# 読み込んだのち、Python 2 との互換性のためにデコード\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# テキストの長さは含まれる文字数\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "broken-castle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# テキストの最初の 250文字を参照\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "requested-think",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 unique characters\n"
     ]
    }
   ],
   "source": [
    "# ファイル中のユニークな文字の数\n",
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "intensive-awareness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-captain",
   "metadata": {},
   "source": [
    "## テキストの処理\n",
    "### テキストのベクトル化\n",
    "訓練をする前に、文字列を数値表現に変換する必要があります。2つの参照テーブルを作成します。一つは文字を数字に変換するもの、もう一つは数字を文字に変換するものです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "committed-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# それぞれの文字からインデックスへの対応表を作成\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-things",
   "metadata": {},
   "source": [
    "これで、それぞれの文字を整数で表現できました。文字を、0 からlen(unique) までのインデックスに変換していることに注意してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "atlantic-grammar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\n':   0,\n",
      "  ' ' :   1,\n",
      "  '!' :   2,\n",
      "  '$' :   3,\n",
      "  '&' :   4,\n",
      "  \"'\" :   5,\n",
      "  ',' :   6,\n",
      "  '-' :   7,\n",
      "  '.' :   8,\n",
      "  '3' :   9,\n",
      "  ':' :  10,\n",
      "  ';' :  11,\n",
      "  '?' :  12,\n",
      "  'A' :  13,\n",
      "  'B' :  14,\n",
      "  'C' :  15,\n",
      "  'D' :  16,\n",
      "  'E' :  17,\n",
      "  'F' :  18,\n",
      "  'G' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "subsequent-xerox",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'First Citizen' ---- characters mapped to int ---- > [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
     ]
    }
   ],
   "source": [
    "# テキストの最初の 13 文字がどのように整数に変換されるかを見てみる\n",
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-explanation",
   "metadata": {},
   "source": [
    "### 予測タスク\n",
    "\n",
    "**ある文字、あるいは文字列が与えられたとき、もっともありそうな次の文字はなにか？これが、モデルを訓練してやらせたいタスク** です。モデルへの入力は文字列であり、モデルが出力、つまりそれぞれの時点での次の文字を予測をするようにモデルを訓練します。\n",
    "\n",
    "RNN はすでに見た要素に基づく内部状態を保持しているため、この時点までに計算されたすべての文字を考えると、次の文字は何でしょうか？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-attack",
   "metadata": {},
   "source": [
    "### 訓練用サンプルとターゲットを作成\n",
    "\n",
    "つぎに、テキストをサンプルシーケンスに分割します。それぞれの入力シーケンスは、元のテキストからの seq_length 個の文字を含みます。\n",
    "\n",
    "入力シーケンスそれぞれに対して、対応するターゲットは同じ長さのテキストを含みますが、1文字ずつ右にシフトしたものです。\n",
    "\n",
    "そのため、テキストを seq_length+1 のかたまりに分割します。たとえば、 seq_length が 4 で、テキストが \"Hello\" だとします。入力シーケンスは \"Hell\" で、ターゲットシーケンスは \"ello\" となります。\n",
    "\n",
    "これを行うために、最初に [tf.data.Dataset.from_tensor_slices](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices) 関数を使ってテキストベクトルを文字インデックスの連続に変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "muslim-maryland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "# ひとつの入力としたいシーケンスの文字数としての最大の長さ\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "# 訓練用サンプルとターゲットを作る\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "banner-shift",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 47, 56, ..., 45,  8,  0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ambient-bundle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115394,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-composite",
   "metadata": {},
   "source": [
    "batch メソッドを使うと、個々の文字を求める長さのシーケンスに簡単に変換できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cordless-eagle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
      "\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
      "\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
      "'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-hybrid",
   "metadata": {},
   "source": [
    "シーケンスそれぞれに対して、map メソッドを使って各バッチに単純な関数を適用することで、複製とシフトを行い、入力テキストとターゲットテキストを生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unusual-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-edition",
   "metadata": {},
   "source": [
    "最初のサンプルの入力とターゲットを出力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "light-grammar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
      "Target data: 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "    print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-retrieval",
   "metadata": {},
   "source": [
    "これらのベクトルのインデックスそれぞれが一つのタイムステップとして処理されます。タイムステップ 0 の入力として、モデルは \"F\" のインデックスを受け取り、次の文字として \"i\" のインデックスを予測しようとします。次のタイムステップでもおなじことをしますが、**RNN は現在の入力文字に加えて、過去のステップのコンテキストも考慮** します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "alternative-evans",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 18 ('F')\n",
      "  expected output: 47 ('i')\n",
      "Step    1\n",
      "  input: 47 ('i')\n",
      "  expected output: 56 ('r')\n",
      "Step    2\n",
      "  input: 56 ('r')\n",
      "  expected output: 57 ('s')\n",
      "Step    3\n",
      "  input: 57 ('s')\n",
      "  expected output: 58 ('t')\n",
      "Step    4\n",
      "  input: 58 ('t')\n",
      "  expected output: 1 (' ')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-reference",
   "metadata": {},
   "source": [
    "### 訓練用バッチの作成\n",
    "[tf.data](https://www.tensorflow.org/api_docs/python/tf/data) を使ってテキストを分割し、扱いやすいシーケンスにします。しかし、このデータをモデルに供給する前に、データをシャッフルしてバッチにまとめる必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "proprietary-jacket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチサイズ\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# データセットをシャッフルするためのバッファサイズ\n",
    "# （TF data は可能性として無限長のシーケンスでも使えるように設計されています。\n",
    "# このため、シーケンス全体をメモリ内でシャッフルしようとはしません。\n",
    "# その代わりに、要素をシャッフルするためのバッファを保持しています）\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-adobe",
   "metadata": {},
   "source": [
    "### モデルの構築\n",
    "\n",
    "[tf.keras.Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) を使ってモデルを定義します。この簡単な例では、モデルの定義に3つのレイヤーを使用しています。\n",
    "\n",
    "- [tf.keras.layers.Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding): 入力レイヤー。それぞれの文字を表す数を embedding_dim　次元のベクトルに変換する、訓練可能な参照テーブル。\n",
    "- [tf.keras.layers.GRU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU): サイズが units=rnn_units のRNNの一種（ここに LSTM レイヤーを使うこともできる）。\n",
    "- [tf.keras.layers.Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense): vocab_size の出力を持つ、出力レイヤー。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "intellectual-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文字数で表されるボキャブラリーの長さ\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# 埋め込みベクトルの次元\n",
    "embedding_dim = 256\n",
    "\n",
    "# RNN ユニットの数\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mediterranean-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "official-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-laundry",
   "metadata": {},
   "source": [
    "1文字ごとにモデルは埋め込みベクトルを検索し、その埋め込みベクトルを入力として GRU を 1 タイムステップ実行します。そして Dense レイヤーを適用して、次の文字の対数尤度を予測するロジットを生成します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-refund",
   "metadata": {},
   "source": [
    "## モデルを試す\n",
    "期待通りに動作するかどうかを確認するためモデルを動かしてみましょう。\n",
    "\n",
    "最初に、出力の shape を確認します。\n",
    "\n",
    "**※バージョンの問題か、build_model関数を呼び出して動かすたびに、Jupyterカーネルが落ちてしまう。⇒一旦コメントアウトし、Google Colabで試した結果を載せる。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adopted-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for input_example_batch, target_example_batch in dataset.take(1):\n",
    "#   example_batch_predictions = model(input_example_batch)\n",
    "#   print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fitting-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (64, 100, 65) # (batch_size, sequence_length, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-broadcasting",
   "metadata": {},
   "source": [
    "上記の例では、入力のシーケンスの長さは 100 ですが、モデルはどのような長さの入力でも実行できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "coastal-mentor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           16640     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 65)            66625     \n",
      "=================================================================\n",
      "Total params: 4,021,569\n",
      "Trainable params: 4,021,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-split",
   "metadata": {},
   "source": [
    "モデルから実際の予測を得るには出力の分布からサンプリングを行う必要があります。この分布は、文字ボキャブラリー全体のロジットで定義されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-little",
   "metadata": {},
   "source": [
    "> Note: この分布から サンプリング するということが重要です。なぜなら、分布の argmax をとったのでは、モデルは簡単にループしてしまうからです。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-musical",
   "metadata": {},
   "source": [
    "バッチ中の最初のサンプルで試してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "provincial-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "# sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-compiler",
   "metadata": {},
   "source": [
    "これにより、タイムステップそれぞれにおいて、次の文字のインデックスの予測が得られます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "plain-circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampled_indices"
   ]
  },
  {
   "cell_type": "raw",
   "id": "hispanic-drunk",
   "metadata": {},
   "source": [
    "array([62, 51, 14, 46,  3, 56, 24, 16, 49,  9, 21,  8, 31, 38, 25, 49, 45,\n",
    "       55,  2, 57, 37, 60, 14, 54, 57, 21, 28, 44, 17, 32, 24, 44, 18, 23,\n",
    "       43, 62,  7, 49, 14, 58, 35, 59,  2, 40,  9, 26, 51,  6, 37, 61, 28,\n",
    "        5,  2, 47, 61, 45, 55, 61, 22, 57,  2, 10, 49, 44, 23, 52,  7, 61,\n",
    "       11, 52, 22, 35, 62, 14, 42,  5, 28,  1, 26, 33, 14, 27, 43, 30, 40,\n",
    "       39,  7, 22, 19, 38, 25, 16,  0, 43, 23, 59, 59, 61, 56, 28])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-jewel",
   "metadata": {},
   "source": [
    "これらをデコードすることで、この訓練前のモデルによる予測テキストをみることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "regular-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "# print()\n",
    "# print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "floral-clothing",
   "metadata": {},
   "source": [
    "Input: \n",
    " 'table shuns your high request.\\nFirst if all obstacles were cut away,\\nAnd that my path were even to t'\n",
    "\n",
    "Next Char Predictions: \n",
    " \"xmBh$rLDk3I.SZMkgq!sYvBpsIPfETLfFKex-kBtWu!b3Nm,YwP'!iwgqwJs!:kfKn-w;nJWxBd'P NUBOeRba-JGZMD\\neKuuwrP\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-popularity",
   "metadata": {},
   "source": [
    "## モデルの訓練\n",
    "\n",
    "ここまでくれば問題は標準的な分類問題として扱うことができます。これまでの RNN の状態と、いまのタイムステップの入力が与えられ、次の文字のクラスを予測します。\n",
    "\n",
    "### オプティマイザと損失関数の付加\n",
    "この場合、標準の [tf.keras.losses.sparse_categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparse_categorical_crossentropy) 損失関数が使えます。予測の最後の次元に適用されるからです。\n",
    "\n",
    "このモデルはロジットを返すので、from_logits フラグをセットする必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "tired-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss(labels, logits):\n",
    "#   return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "# example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "# print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "# print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "federal-insight",
   "metadata": {},
   "source": [
    "Prediction shape:  (64, 100, 65)  # (batch_size, sequence_length, vocab_size)\n",
    "scalar_loss:       4.174704\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-layout",
   "metadata": {},
   "source": [
    "[tf.keras.Model.compile](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile) を使って、訓練手順を定義します。\n",
    "既定の引数を持った [tf.keras.optimizers.Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) と、先ほどの loss 関数を使用しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "amateur-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-mileage",
   "metadata": {},
   "source": [
    "## チェックポイントの構成\n",
    "[tf.keras.callbacks.ModelCheckpoint](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint) を使って、訓練中にチェックポイントを保存するようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "blessed-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# チェックポイントが保存されるディレクトリ\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# チェックポイントファイルの名称\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-chicken",
   "metadata": {},
   "source": [
    "## 訓練の実行\n",
    "訓練時間を適切に保つために、10エポックを使用してモデルを訓練します。Google Colab を使用する場合には、訓練を高速化するためにランタイムを GPU に設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fitting-iceland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "progressive-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "joint-maria",
   "metadata": {},
   "source": [
    "Epoch 1/10\n",
    "172/172 [==============================] - 12s 58ms/step - loss: 3.2086\n",
    "Epoch 2/10\n",
    "172/172 [==============================] - 11s 61ms/step - loss: 2.0416\n",
    "Epoch 3/10\n",
    "172/172 [==============================] - 11s 61ms/step - loss: 1.7328\n",
    "Epoch 4/10\n",
    "172/172 [==============================] - 11s 60ms/step - loss: 1.5596\n",
    "Epoch 5/10\n",
    "172/172 [==============================] - 11s 58ms/step - loss: 1.4629\n",
    "Epoch 6/10\n",
    "172/172 [==============================] - 11s 58ms/step - loss: 1.3944\n",
    "Epoch 7/10\n",
    "172/172 [==============================] - 11s 58ms/step - loss: 1.3479\n",
    "Epoch 8/10\n",
    "172/172 [==============================] - 11s 59ms/step - loss: 1.3041\n",
    "Epoch 9/10\n",
    "172/172 [==============================] - 11s 60ms/step - loss: 1.2721\n",
    "Epoch 10/10\n",
    "172/172 [==============================] - 11s 60ms/step - loss: 1.2381"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-cache",
   "metadata": {},
   "source": [
    "## テキスト生成\n",
    "\n",
    "### 最終チェックポイントの復元\n",
    "予測ステップを単純にするため、バッチサイズ 1 を使用します。\n",
    "\n",
    "RNN が状態をタイムステップからタイムステップへと渡す仕組みのため、モデルは一度構築されると固定されたバッチサイズしか受け付けられません。\n",
    "\n",
    "モデルを異なる batch_size で実行するためには、モデルを再構築し、チェックポイントから重みを復元する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "revised-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "worldwide-literature",
   "metadata": {},
   "source": [
    "'./training_checkpoints/ckpt_10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "configured-letter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "# model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "# model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "noticed-robert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           16640     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 65)            66625     \n",
      "=================================================================\n",
      "Total params: 4,021,569\n",
      "Trainable params: 4,021,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-standard",
   "metadata": {},
   "source": [
    "## 予測ループ\n",
    "下記のコードブロックでテキストを生成します。\n",
    "\n",
    "- 最初に、開始文字列を選択し、RNN の状態を初期化して、生成する文字数を設定します。\n",
    "\n",
    "- 開始文字列と RNN の状態を使って、次の文字の予測分布を得ます。\n",
    "\n",
    "- つぎに、カテゴリー分布を使用して、予測された文字のインデックスを計算します。この予測された文字をモデルの次の入力にします。\n",
    "\n",
    "- モデルによって返された RNN の状態はモデルにフィードバックされるため、1つの文字だけでなく、より多くのコンテキストを持つことになります。つぎの文字を予測した後、更新された RNN の状態が再びモデルにフィードバックされます。こうしてモデルは以前に予測した文字からさらにコンテキストを得ることで学習するのです。\n",
    "\n",
    "To generate text the model's output is fed back to the input\n",
    "\n",
    "生成されたテキストを見ると、モデルがどこを大文字にするかや、段落の区切り方、シェークスピアらしい書き言葉を真似ることを知っていることがわかります。しかし、訓練のエポック数が少ないので、まだ一貫した文章を生成するところまでは学習していません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "flush-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_text(model, start_string):\n",
    "#   # 評価ステップ（学習済みモデルを使ったテキスト生成）\n",
    "\n",
    "#   # 生成する文字数\n",
    "#   num_generate = 1000\n",
    "\n",
    "#   # 開始文字列を数値に変換（ベクトル化）\n",
    "#   input_eval = [char2idx[s] for s in start_string]\n",
    "#   input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "#   # 結果を保存する空文字列\n",
    "#   text_generated = []\n",
    "\n",
    "#   # 低い temperature　は、より予測しやすいテキストをもたらし\n",
    "#   # 高い temperature は、より意外なテキストをもたらす\n",
    "#   # 実験により最適な設定を見つけること\n",
    "#   temperature = 1.0\n",
    "\n",
    "#   # ここではバッチサイズ　== 1\n",
    "#   model.reset_states()\n",
    "#   for i in range(num_generate):\n",
    "#       predictions = model(input_eval)\n",
    "#       # バッチの次元を削除\n",
    "#       predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "#       # カテゴリー分布をつかってモデルから返された文字を予測 \n",
    "#       predictions = predictions / temperature\n",
    "#       predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "#       # 過去の隠れ状態とともに予測された文字をモデルへのつぎの入力として渡す\n",
    "#       input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "#       text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "#   return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "declared-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(generate_text(model, start_string=u\"ROMEO: \"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "electrical-print",
   "metadata": {},
   "source": [
    "ROMEO: Take thee,\n",
    "To hear the senate, which, I could forget:\n",
    "His concainly and lose them but still come\n",
    "To plain upon their state, Vaughty man it,\n",
    "And I am come, the life of England's young,\n",
    "Even to than to with us\n",
    "Did shall stem to be, so early in the school!\n",
    "Come, mother, time to be armourd's retert: if reven you gow, and most control?\n",
    "\n",
    "NORTHUMBERLAND:\n",
    "How now, being no thunder-thanks:\n",
    "I, 'twas great powerful bosom on.\n",
    "\n",
    "AUTOLYCUS:\n",
    "Ay, that do as have but lose his daughters forth\n",
    "The bidg of very hardless to gaze our sweet sounded queen:\n",
    "In patience and unwiltuse myself\n",
    "To Claudio come to would come. Out of Naples.\n",
    "Unless they may be absonutuea,\n",
    "Because they come to know this mother, but stoop named\n",
    "To say so expeech the gen'for the people my gazed thus?\n",
    "Heavy speedily, withalong the duke!\n",
    "\n",
    "PETRUCHIO:\n",
    "Marry, sir.\n",
    "\n",
    "Clown:\n",
    "It is within this muscarry: Well!\n",
    "\n",
    "LUCENTIO:\n",
    "Carth Pauch of Buckinghampines\n",
    "As 'ecreech'd--but three part efracation,\n",
    "question, which is the stone celent pound o' the dove--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-commander",
   "metadata": {},
   "source": [
    "**この結果を改善するもっとも簡単な方法は、もっと長く訓練することです（EPOCHS=30 を試してみましょう）。**\n",
    "\n",
    "**また、異なる初期文字列を使ったり、モデルの精度を向上させるためにもうひとつ RNN レイヤーを加えたり、temperature パラメータを調整して、よりランダム性の強い、あるいは、弱い予測を試してみたりすることができます。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-habitat",
   "metadata": {},
   "source": [
    "## 上級編： 訓練のカスタマイズ\n",
    "上記の訓練手順は単純ですが、制御できるところがそれほどありません。\n",
    "\n",
    "モデルを手動で実行する方法を見てきたので、訓練ループを展開し、自分で実装してみましょう。このことが、たとえばモデルのオープンループによる出力を安定化するための カリキュラム学習 を実装するための出発点になります。\n",
    "\n",
    "勾配を追跡するために [tf.GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape) を使用します。このアプローチについての詳細を学ぶには、 [eager execution guide](https://www.tensorflow.org/guide/eager) をお読みください。\n",
    "\n",
    "この手順は下記のように動作します。\n",
    "\n",
    "- 最初に、RNN の状態を初期化する。[tf.keras.Model.reset_states](https://www.tensorflow.org/api_docs/python/tf/keras/Model#reset_states) メソッドを呼び出すことでこれを実行する。\n",
    "\n",
    "- つぎに、（1バッチずつ）データセットを順番に処理し、それぞれのバッチに対する予測値を計算する。\n",
    "\n",
    "- [tf.GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape) をオープンし、そのコンテキストで、予測値と損失を計算する。\n",
    "\n",
    "- tf.GradientTape.grads メソッドを使って、モデルの変数に対する損失の勾配を計算する。\n",
    "\n",
    "- 最後に、オプティマイザの tf.train.Optimizer.apply_gradients メソッドを使って、逆方向の処理を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "solar-closer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_model(\n",
    "#   vocab_size = len(vocab),\n",
    "#   embedding_dim=embedding_dim,\n",
    "#   rnn_units=rnn_units,\n",
    "#   batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "nonprofit-advertiser",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aquatic-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "# def train_step(inp, target):\n",
    "#   with tf.GradientTape() as tape:\n",
    "#     predictions = model(inp)\n",
    "#     loss = tf.reduce_mean(\n",
    "#         tf.keras.losses.sparse_categorical_crossentropy(\n",
    "#             target, predictions, from_logits=True))\n",
    "#   grads = tape.gradient(loss, model.trainable_variables)\n",
    "#   optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "#   return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fifth-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 訓練ステップ\n",
    "# EPOCHS = 10\n",
    "\n",
    "# for epoch in range(EPOCHS):\n",
    "#   start = time.time()\n",
    "\n",
    "#   # 各エポックの最初に、隠れ状態を初期化する\n",
    "#   # 最初は隠れ状態は None\n",
    "#   hidden = model.reset_states()\n",
    "\n",
    "#   for (batch_n, (inp, target)) in enumerate(dataset):\n",
    "#     loss = train_step(inp, target)\n",
    "\n",
    "#     if batch_n % 100 == 0:\n",
    "#       template = 'Epoch {} Batch {} Loss {}'\n",
    "#       print(template.format(epoch+1, batch_n, loss))\n",
    "\n",
    "#   # 5エポックごとにモデル（のチェックポイント）を保存する\n",
    "#   if (epoch + 1) % 5 == 0:\n",
    "#     model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
    "\n",
    "#   print ('Epoch {} Loss {:.4f}'.format(epoch+1, loss))\n",
    "#   print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "\n",
    "# model.save_weights(checkpoint_prefix.format(epoch=epoch))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "formed-middle",
   "metadata": {},
   "source": [
    "Epoch 1 Batch 0 Loss 4.175105094909668\n",
    "Epoch 1 Batch 100 Loss 2.362163543701172\n",
    "Epoch 1 Loss 2.1442\n",
    "Time taken for 1 epoch 11.697978019714355 sec\n",
    "\n",
    "Epoch 2 Batch 0 Loss 2.1487984657287598\n",
    "Epoch 2 Batch 100 Loss 1.9109301567077637\n",
    "Epoch 2 Loss 1.8172\n",
    "Time taken for 1 epoch 10.722083330154419 sec\n",
    "\n",
    "Epoch 3 Batch 0 Loss 1.7685736417770386\n",
    "Epoch 3 Batch 100 Loss 1.647067904472351\n",
    "Epoch 3 Loss 1.6334\n",
    "Time taken for 1 epoch 10.775439739227295 sec\n",
    "\n",
    "Epoch 4 Batch 0 Loss 1.6337007284164429\n",
    "Epoch 4 Batch 100 Loss 1.5301438570022583\n",
    "Epoch 4 Loss 1.5278\n",
    "Time taken for 1 epoch 10.789868354797363 sec\n",
    "\n",
    "Epoch 5 Batch 0 Loss 1.458348035812378\n",
    "Epoch 5 Batch 100 Loss 1.5004372596740723\n",
    "Epoch 5 Loss 1.4235\n",
    "Time taken for 1 epoch 10.792716026306152 sec\n",
    "\n",
    "Epoch 6 Batch 0 Loss 1.3983813524246216\n",
    "Epoch 6 Batch 100 Loss 1.381321668624878\n",
    "Epoch 6 Loss 1.3890\n",
    "Time taken for 1 epoch 10.691157817840576 sec\n",
    "\n",
    "Epoch 7 Batch 0 Loss 1.3263795375823975\n",
    "Epoch 7 Batch 100 Loss 1.354075312614441\n",
    "Epoch 7 Loss 1.3761\n",
    "Time taken for 1 epoch 10.669045448303223 sec\n",
    "\n",
    "Epoch 8 Batch 0 Loss 1.3285146951675415\n",
    "Epoch 8 Batch 100 Loss 1.2696127891540527\n",
    "Epoch 8 Loss 1.3235\n",
    "Time taken for 1 epoch 10.667819499969482 sec\n",
    "\n",
    "Epoch 9 Batch 0 Loss 1.2003755569458008\n",
    "Epoch 9 Batch 100 Loss 1.3214586973190308\n",
    "Epoch 9 Loss 1.3046\n",
    "Time taken for 1 epoch 10.643569469451904 sec\n",
    "\n",
    "Epoch 10 Batch 0 Loss 1.1768802404403687\n",
    "Epoch 10 Batch 100 Loss 1.248146414756775\n",
    "Epoch 10 Loss 1.2627\n",
    "Time taken for 1 epoch 10.708478450775146 sec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-legend",
   "metadata": {},
   "source": [
    "【問題2】（アドバンス課題）様々な手法を実行\n",
    "TensorFLowやGoogle AI ResearchのGitHubリポジトリには、定番のモデルから最新のモデルまで多様なコードが公開されています。これらから興味あるものを選び実行してください。\n",
    "\n",
    "\n",
    "なお、これらのコードは初学者向けではないため、巨大なデータセットのダウンロードが必要な場合など、実行が簡単ではないこともあります。そういった場合は、コードリーディングを行ってください。\n",
    "\n",
    "\n",
    "models/research at master · tensorflow/models\n",
    "\n",
    "\n",
    "google-research/google-research: Google AI Research\n",
    "\n",
    "\n",
    "更新日が古いものはPythonやTensorFlowのバージョンが古く、扱いずらい場合があります。新しいものから見ることを推奨します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-exposure",
   "metadata": {},
   "source": [
    "## 3.異なるフレームワークへの書き換え\n",
    "\n",
    "「ディープラーニングフレームワーク1」で作成した4種類のデータセットを扱うTensorFLowのコードを異なるフレームワークに変更していきます。\n",
    "\n",
    "\n",
    "- Iris（Iris-versicolorとIris-virginicaのみの2値分類）\n",
    "- Iris（3種類全ての目的変数を使用して多値分類）\n",
    "- House Prices\n",
    "- MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-blink",
   "metadata": {},
   "source": [
    "### Kerasへの書き換え\n",
    "KerasはTensorFLowに含まれるtf.kerasモジュールを使用してください。\n",
    "\n",
    "\n",
    "KerasにはSequentialモデルかFunctional APIかなど書き方に種類がありますが、これは指定しません。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-girlfriend",
   "metadata": {},
   "source": [
    "## 【問題3】Iris（2値分類）をKerasで学習\n",
    "TensorFlowによるIrisデータセットに対する2値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "structural-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras import backend as K \n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "expired-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "df = pd.read_csv(\"Iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ecological-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\") | (df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fiscal-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy 配列に変換\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "weighted-russian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルを数値に変換\n",
    "y[y == \"Iris-versicolor\"] = 0\n",
    "y[y == \"Iris-virginica\"] = 1\n",
    "y = y.astype(np.int64)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "oriented-swift",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (64, 4)\n",
      "X_val.shape (16, 4)\n",
      "y_train (64, 1)\n",
      "y_val.shape (16, 1)\n"
     ]
    }
   ],
   "source": [
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "print('X_train.shape', X_train.shape)\n",
    "print('X_val.shape', X_val.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('y_val.shape', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "exceptional-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self.X = X[shuffle_index]\n",
    "        self.y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self.X[p0:p1], self.y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self.X[p0:p1], self.y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "duplicate-occupation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               640       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,961\n",
      "Trainable params: 8,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.001\n",
    "batch_size = 10\n",
    "num_epochs = 30\n",
    "\n",
    "# モデル構築\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu, input_shape=(4,)))\n",
    "model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "perceived-criminal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 16 samples\n",
      "Epoch 1/30\n",
      "64/64 [==============================] - 1s 23ms/sample - loss: 0.6726 - accuracy: 0.5312 - val_loss: 0.6508 - val_accuracy: 0.7500\n",
      "Epoch 2/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6573 - accuracy: 0.6250 - val_loss: 0.6172 - val_accuracy: 0.8125\n",
      "Epoch 3/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6204 - accuracy: 0.7812 - val_loss: 0.6719 - val_accuracy: 0.3750\n",
      "Epoch 4/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6106 - accuracy: 0.5469 - val_loss: 0.6418 - val_accuracy: 0.4375\n",
      "Epoch 5/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6015 - accuracy: 0.8125 - val_loss: 0.5702 - val_accuracy: 0.8750\n",
      "Epoch 6/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.5768 - accuracy: 0.8906 - val_loss: 0.6064 - val_accuracy: 0.5625\n",
      "Epoch 7/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.5542 - accuracy: 0.7656 - val_loss: 0.5578 - val_accuracy: 0.9375\n",
      "Epoch 8/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.5311 - accuracy: 0.7969 - val_loss: 0.5672 - val_accuracy: 0.8125\n",
      "Epoch 9/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.5257 - accuracy: 0.7812 - val_loss: 0.5466 - val_accuracy: 0.8125\n",
      "Epoch 10/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.5197 - accuracy: 0.7188 - val_loss: 0.5249 - val_accuracy: 0.8125\n",
      "Epoch 11/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.5092 - accuracy: 0.8594 - val_loss: 0.4667 - val_accuracy: 0.8750\n",
      "Epoch 12/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.4730 - accuracy: 0.9219 - val_loss: 0.5208 - val_accuracy: 0.8125\n",
      "Epoch 13/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.4599 - accuracy: 0.8594 - val_loss: 0.4736 - val_accuracy: 0.9375\n",
      "Epoch 14/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.4360 - accuracy: 0.9375 - val_loss: 0.4356 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.4245 - accuracy: 0.9688 - val_loss: 0.4121 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.4007 - accuracy: 0.9688 - val_loss: 0.4144 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.3931 - accuracy: 0.9219 - val_loss: 0.4101 - val_accuracy: 0.9375\n",
      "Epoch 18/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.3689 - accuracy: 0.9375 - val_loss: 0.3626 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.3574 - accuracy: 0.9531 - val_loss: 0.3404 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.3358 - accuracy: 0.9531 - val_loss: 0.3547 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.3313 - accuracy: 0.9375 - val_loss: 0.3112 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.3163 - accuracy: 0.9375 - val_loss: 0.3282 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.3048 - accuracy: 0.9531 - val_loss: 0.2738 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.3028 - accuracy: 0.9375 - val_loss: 0.2963 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.2707 - accuracy: 0.9531 - val_loss: 0.2550 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.2639 - accuracy: 0.9688 - val_loss: 0.2410 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.2567 - accuracy: 0.9688 - val_loss: 0.2410 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.2370 - accuracy: 0.9531 - val_loss: 0.2437 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.2466 - accuracy: 0.9531 - val_loss: 0.2126 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.2504 - accuracy: 0.9375 - val_loss: 0.2183 - val_accuracy: 1.0000\n",
      "20/1 [========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 336us/sample - loss: 0.2879 - accuracy: 0.9000\n",
      "Test loss: 0.2879003882408142\n",
      "Test accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "# モデルコンパイル\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 学習\n",
    "history = model.fit(X_train, y_train,\n",
    "                   batch_size=batch_size,\n",
    "                   epochs=num_epochs,\n",
    "                   verbose=1,\n",
    "                   validation_data=(X_val,y_val))\n",
    "\n",
    "# 推定結果(確率)\n",
    "y_pred_proba = model.predict(X_train)[:,0]\n",
    "# 確率を0, 1に変換\n",
    "y_pred = np.where(y_pred_proba > 0.5, 1, 0)\n",
    "\n",
    "# 指標値計算\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-season",
   "metadata": {},
   "source": [
    "## 【問題4】Iris（多値分類）をKerasで学習\n",
    "TensorFlowによるIrisデータセットに対する3値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "silver-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "viral-egyptian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データセットの読み込み\n",
    "df = pd.read_csv(\"Iris.csv\")\n",
    "\n",
    "# データフレームから条件抽出\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "\n",
    "# NumPy 配列に変換\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-setosa'] = 0\n",
    "y[y=='Iris-versicolor'] = 1\n",
    "y[y=='Iris-virginica'] = 2\n",
    "# y = y.astype(np.int64)[:, np.newaxis]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "revised-input",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ワンホット処理\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_one_hot = enc.fit_transform(y[:, np.newaxis])\n",
    "y_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "stopped-contents",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (96, 4)\n",
      "X_val.shape (24, 4)\n",
      "y_train (96, 3)\n",
      "y_val.shape (24, 3)\n"
     ]
    }
   ],
   "source": [
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "print('X_train.shape', X_train.shape)\n",
    "print('X_val.shape', X_val.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('y_val.shape', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "parallel-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "provincial-proposition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               640       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 9,091\n",
      "Trainable params: 9,091\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.001\n",
    "batch_size = 10\n",
    "num_epochs = 30\n",
    "\n",
    "# モデル構築\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu, input_shape=(4,)))\n",
    "model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(3, activation=tf.nn.softmax))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "still-touch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96 samples, validate on 24 samples\n",
      "Epoch 1/30\n",
      "96/96 [==============================] - 1s 12ms/sample - loss: 1.1344 - accuracy: 0.5417 - val_loss: 0.8059 - val_accuracy: 0.7083\n",
      "Epoch 2/30\n",
      "96/96 [==============================] - 0s 930us/sample - loss: 0.7683 - accuracy: 0.8542 - val_loss: 0.6991 - val_accuracy: 0.9167\n",
      "Epoch 3/30\n",
      "96/96 [==============================] - 0s 935us/sample - loss: 0.6330 - accuracy: 0.7500 - val_loss: 0.6082 - val_accuracy: 0.7083\n",
      "Epoch 4/30\n",
      "96/96 [==============================] - 0s 934us/sample - loss: 0.5442 - accuracy: 0.7396 - val_loss: 0.5288 - val_accuracy: 0.8333\n",
      "Epoch 5/30\n",
      "96/96 [==============================] - 0s 979us/sample - loss: 0.4702 - accuracy: 0.9167 - val_loss: 0.4696 - val_accuracy: 0.7500\n",
      "Epoch 6/30\n",
      "96/96 [==============================] - 0s 943us/sample - loss: 0.4124 - accuracy: 0.9062 - val_loss: 0.4310 - val_accuracy: 0.9167\n",
      "Epoch 7/30\n",
      "96/96 [==============================] - 0s 925us/sample - loss: 0.3737 - accuracy: 0.9375 - val_loss: 0.4065 - val_accuracy: 0.8333\n",
      "Epoch 8/30\n",
      "96/96 [==============================] - 0s 927us/sample - loss: 0.3442 - accuracy: 0.9375 - val_loss: 0.3840 - val_accuracy: 0.8750\n",
      "Epoch 9/30\n",
      "96/96 [==============================] - 0s 960us/sample - loss: 0.3125 - accuracy: 0.9167 - val_loss: 0.3620 - val_accuracy: 0.9167\n",
      "Epoch 10/30\n",
      "96/96 [==============================] - 0s 925us/sample - loss: 0.2821 - accuracy: 0.9688 - val_loss: 0.3445 - val_accuracy: 0.9167\n",
      "Epoch 11/30\n",
      "96/96 [==============================] - 0s 945us/sample - loss: 0.2685 - accuracy: 0.9688 - val_loss: 0.3443 - val_accuracy: 0.9167\n",
      "Epoch 12/30\n",
      "96/96 [==============================] - 0s 964us/sample - loss: 0.2569 - accuracy: 0.9479 - val_loss: 0.3122 - val_accuracy: 0.9167\n",
      "Epoch 13/30\n",
      "96/96 [==============================] - 0s 916us/sample - loss: 0.2205 - accuracy: 0.9688 - val_loss: 0.3038 - val_accuracy: 0.9167\n",
      "Epoch 14/30\n",
      "96/96 [==============================] - 0s 959us/sample - loss: 0.2043 - accuracy: 0.9792 - val_loss: 0.2970 - val_accuracy: 0.9167\n",
      "Epoch 15/30\n",
      "96/96 [==============================] - 0s 931us/sample - loss: 0.1869 - accuracy: 0.9792 - val_loss: 0.2800 - val_accuracy: 0.9167\n",
      "Epoch 16/30\n",
      "96/96 [==============================] - 0s 949us/sample - loss: 0.1766 - accuracy: 0.9792 - val_loss: 0.2685 - val_accuracy: 0.9167\n",
      "Epoch 17/30\n",
      "96/96 [==============================] - 0s 1ms/sample - loss: 0.1663 - accuracy: 0.9688 - val_loss: 0.2662 - val_accuracy: 0.9167\n",
      "Epoch 18/30\n",
      "96/96 [==============================] - 0s 937us/sample - loss: 0.1471 - accuracy: 0.9792 - val_loss: 0.2523 - val_accuracy: 0.9167\n",
      "Epoch 19/30\n",
      "96/96 [==============================] - 0s 908us/sample - loss: 0.1389 - accuracy: 0.9792 - val_loss: 0.2376 - val_accuracy: 0.9167\n",
      "Epoch 20/30\n",
      "96/96 [==============================] - 0s 952us/sample - loss: 0.1362 - accuracy: 0.9896 - val_loss: 0.2583 - val_accuracy: 0.9167\n",
      "Epoch 21/30\n",
      "96/96 [==============================] - 0s 995us/sample - loss: 0.1199 - accuracy: 0.9792 - val_loss: 0.2236 - val_accuracy: 0.9167\n",
      "Epoch 22/30\n",
      "96/96 [==============================] - 0s 1ms/sample - loss: 0.1171 - accuracy: 0.9896 - val_loss: 0.2529 - val_accuracy: 0.9167\n",
      "Epoch 23/30\n",
      "96/96 [==============================] - 0s 922us/sample - loss: 0.1052 - accuracy: 0.9688 - val_loss: 0.2140 - val_accuracy: 0.9167\n",
      "Epoch 24/30\n",
      "96/96 [==============================] - 0s 983us/sample - loss: 0.1364 - accuracy: 0.9583 - val_loss: 0.2925 - val_accuracy: 0.9167\n",
      "Epoch 25/30\n",
      "96/96 [==============================] - 0s 966us/sample - loss: 0.1153 - accuracy: 0.9688 - val_loss: 0.2087 - val_accuracy: 0.9167\n",
      "Epoch 26/30\n",
      "96/96 [==============================] - 0s 952us/sample - loss: 0.0945 - accuracy: 0.9792 - val_loss: 0.2124 - val_accuracy: 0.9167\n",
      "Epoch 27/30\n",
      "96/96 [==============================] - 0s 948us/sample - loss: 0.0891 - accuracy: 0.9792 - val_loss: 0.2308 - val_accuracy: 0.9167\n",
      "Epoch 28/30\n",
      "96/96 [==============================] - 0s 949us/sample - loss: 0.0856 - accuracy: 0.9792 - val_loss: 0.2058 - val_accuracy: 0.9167\n",
      "Epoch 29/30\n",
      "96/96 [==============================] - 0s 894us/sample - loss: 0.0907 - accuracy: 0.9792 - val_loss: 0.2237 - val_accuracy: 0.9167\n",
      "Epoch 30/30\n",
      "96/96 [==============================] - 0s 945us/sample - loss: 0.0818 - accuracy: 0.9792 - val_loss: 0.2087 - val_accuracy: 0.9167\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 229us/sample - loss: 0.0728 - accuracy: 1.0000\n",
      "Test loss: 0.07282660156488419\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# モデルコンパイル\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 学習\n",
    "history = model.fit(X_train, y_train,\n",
    "                   batch_size=batch_size,\n",
    "                   epochs=num_epochs,\n",
    "                   verbose=1,\n",
    "                   validation_data=(X_val,y_val))\n",
    "\n",
    "# 推定結果(確率)\n",
    "y_pred_proba = model.predict(X_train)\n",
    "# 確率を0, 1に変換\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# 指標値計算\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-paris",
   "metadata": {},
   "source": [
    "## 【問題5】House PricesをKerasで学習\n",
    "TensorFlowによるHouse Pricesデータセットに対する回帰をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "intense-bibliography",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 1)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データセットの読み込み\n",
    "df = pd.read_csv('train.csv')\n",
    "# データフレームから条件抽出\n",
    "y = df[\"SalePrice\"]\n",
    "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n",
    "\n",
    "# NumPy 配列に変換\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "y = y[:, np.newaxis] # (n_samples, 1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "pretty-wales",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.24769432],\n",
       "       [12.10901093],\n",
       "       [12.31716669],\n",
       "       ...,\n",
       "       [12.49312952],\n",
       "       [11.86446223],\n",
       "       [11.90158345]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# yに対して対数変換を行う\n",
    "\n",
    "y = np.log(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "collect-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化を行う\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_std = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "characteristic-witch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(934, 2)\n",
      "(234, 2)\n",
      "(934, 1)\n",
      "(234, 1)\n"
     ]
    }
   ],
   "source": [
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "soviet-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "encouraging-brunswick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               384       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,705\n",
      "Trainable params: 8,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.001\n",
    "batch_size = 10\n",
    "num_epochs = 30\n",
    "\n",
    "# モデル構築\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu, input_shape=(X.shape[1],)))\n",
    "model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "multiple-links",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 934 samples, validate on 234 samples\n",
      "Epoch 1/30\n",
      "934/934 [==============================] - 1s 1ms/sample - loss: 68.3630 - val_loss: 7.2614\n",
      "Epoch 2/30\n",
      "934/934 [==============================] - 0s 371us/sample - loss: 6.1735 - val_loss: 3.3769\n",
      "Epoch 3/30\n",
      "934/934 [==============================] - 0s 362us/sample - loss: 2.7936 - val_loss: 1.3744\n",
      "Epoch 4/30\n",
      "934/934 [==============================] - 0s 394us/sample - loss: 1.2853 - val_loss: 0.6989\n",
      "Epoch 5/30\n",
      "934/934 [==============================] - 0s 391us/sample - loss: 0.6654 - val_loss: 0.3530\n",
      "Epoch 6/30\n",
      "934/934 [==============================] - 0s 365us/sample - loss: 0.3446 - val_loss: 0.1973\n",
      "Epoch 7/30\n",
      "934/934 [==============================] - 0s 358us/sample - loss: 0.1941 - val_loss: 0.1180\n",
      "Epoch 8/30\n",
      "934/934 [==============================] - 0s 364us/sample - loss: 0.1165 - val_loss: 0.0867\n",
      "Epoch 9/30\n",
      "934/934 [==============================] - 0s 367us/sample - loss: 0.0866 - val_loss: 0.0846\n",
      "Epoch 10/30\n",
      "934/934 [==============================] - 0s 368us/sample - loss: 0.0749 - val_loss: 0.0588\n",
      "Epoch 11/30\n",
      "934/934 [==============================] - 0s 366us/sample - loss: 0.0664 - val_loss: 0.0582\n",
      "Epoch 12/30\n",
      "934/934 [==============================] - 0s 373us/sample - loss: 0.0665 - val_loss: 0.0550\n",
      "Epoch 13/30\n",
      "934/934 [==============================] - 0s 376us/sample - loss: 0.0617 - val_loss: 0.0538\n",
      "Epoch 14/30\n",
      "934/934 [==============================] - 0s 366us/sample - loss: 0.0599 - val_loss: 0.0585\n",
      "Epoch 15/30\n",
      "934/934 [==============================] - 0s 395us/sample - loss: 0.0567 - val_loss: 0.0490\n",
      "Epoch 16/30\n",
      "934/934 [==============================] - 0s 401us/sample - loss: 0.0562 - val_loss: 0.0475\n",
      "Epoch 17/30\n",
      "934/934 [==============================] - 0s 372us/sample - loss: 0.0545 - val_loss: 0.0493\n",
      "Epoch 18/30\n",
      "934/934 [==============================] - 0s 379us/sample - loss: 0.0544 - val_loss: 0.0444\n",
      "Epoch 19/30\n",
      "934/934 [==============================] - 0s 379us/sample - loss: 0.0523 - val_loss: 0.0461\n",
      "Epoch 20/30\n",
      "934/934 [==============================] - 0s 367us/sample - loss: 0.0532 - val_loss: 0.0452\n",
      "Epoch 21/30\n",
      "934/934 [==============================] - 0s 373us/sample - loss: 0.0538 - val_loss: 0.0457\n",
      "Epoch 22/30\n",
      "934/934 [==============================] - 0s 371us/sample - loss: 0.0518 - val_loss: 0.0452\n",
      "Epoch 23/30\n",
      "934/934 [==============================] - 0s 363us/sample - loss: 0.0524 - val_loss: 0.0424\n",
      "Epoch 24/30\n",
      "934/934 [==============================] - 0s 370us/sample - loss: 0.0512 - val_loss: 0.0531\n",
      "Epoch 25/30\n",
      "934/934 [==============================] - 0s 368us/sample - loss: 0.0528 - val_loss: 0.0600\n",
      "Epoch 26/30\n",
      "934/934 [==============================] - 0s 364us/sample - loss: 0.0527 - val_loss: 0.0638\n",
      "Epoch 27/30\n",
      "934/934 [==============================] - 0s 380us/sample - loss: 0.0504 - val_loss: 0.0451\n",
      "Epoch 28/30\n",
      "934/934 [==============================] - 0s 369us/sample - loss: 0.0508 - val_loss: 0.0778\n",
      "Epoch 29/30\n",
      "934/934 [==============================] - 0s 368us/sample - loss: 0.0495 - val_loss: 0.0491\n",
      "Epoch 30/30\n",
      "934/934 [==============================] - 0s 395us/sample - loss: 0.0484 - val_loss: 0.0422\n",
      "Test mse: 0.059111211908190214\n"
     ]
    }
   ],
   "source": [
    "# モデルコンパイル\n",
    "model.compile(loss='mean_squared_error',\n",
    "             optimizer=tf.optimizers.Adam(learning_rate=learning_rate))\n",
    "\n",
    "# 学習\n",
    "history = model.fit(X_train, y_train,\n",
    "                   batch_size=batch_size,\n",
    "                   epochs=num_epochs,\n",
    "                   verbose=1,\n",
    "                   validation_data=(X_val,y_val))\n",
    "\n",
    "# 推定結果\n",
    "y_pred = model.predict(X_train)\n",
    "\n",
    "# 指標値計算\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test mse:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-legislation",
   "metadata": {},
   "source": [
    "## 【問題6】MNISTをKerasで学習\n",
    "TensorFlowによるMNISTデータセットによる画像の多値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "sensitive-passenger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "uint8\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# MNISTのデータセットを読み込み\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(X_train[0].dtype) # uint8\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "delayed-document",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# 前処理\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "adapted-composition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# 平滑化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "print(X_train.shape) # (60000, 784)\n",
    "print(X_test.shape) # (10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "modular-architect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# ワンホット処理\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.fit_transform(y_test[:, np.newaxis])\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_test_one_hot.shape) # (10000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "applicable-marijuana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (48000, 784)\n",
      "X_val.shape (12000, 784)\n",
      "y_train (48000, 10)\n",
      "y_val.shape (12000, 10)\n"
     ]
    }
   ],
   "source": [
    "# trainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2, random_state=0)\n",
    "print('X_train.shape', X_train.shape)\n",
    "print('X_val.shape', X_val.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('y_val.shape', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "absolute-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "vietnamese-paragraph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.001\n",
    "batch_size = 10\n",
    "num_epochs = 30\n",
    "\n",
    "# モデル構築\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu, input_shape=(784,)))\n",
    "model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "shaped-thursday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/30\n",
      "48000/48000 [==============================] - 40s 828us/sample - loss: 0.0141 - accuracy: 0.9968 - val_loss: 0.2138 - val_accuracy: 0.9797\n",
      "Epoch 2/30\n",
      "48000/48000 [==============================] - 40s 825us/sample - loss: 0.0115 - accuracy: 0.9973 - val_loss: 0.2391 - val_accuracy: 0.9785\n",
      "Epoch 3/30\n",
      "48000/48000 [==============================] - 38s 791us/sample - loss: 0.0135 - accuracy: 0.9967 - val_loss: 0.2633 - val_accuracy: 0.9764\n",
      "Epoch 4/30\n",
      "48000/48000 [==============================] - 38s 783us/sample - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.2245 - val_accuracy: 0.9784\n",
      "Epoch 5/30\n",
      "48000/48000 [==============================] - 37s 779us/sample - loss: 0.0132 - accuracy: 0.9969 - val_loss: 0.2210 - val_accuracy: 0.9778\n",
      "Epoch 6/30\n",
      "48000/48000 [==============================] - 39s 809us/sample - loss: 0.0117 - accuracy: 0.9975 - val_loss: 0.2433 - val_accuracy: 0.9783\n",
      "Epoch 7/30\n",
      "48000/48000 [==============================] - 37s 775us/sample - loss: 0.0135 - accuracy: 0.9970 - val_loss: 0.2571 - val_accuracy: 0.9776\n",
      "Epoch 8/30\n",
      "48000/48000 [==============================] - 35s 729us/sample - loss: 0.0140 - accuracy: 0.9971 - val_loss: 0.2535 - val_accuracy: 0.9791\n",
      "Epoch 9/30\n",
      "48000/48000 [==============================] - 35s 730us/sample - loss: 0.0124 - accuracy: 0.9973 - val_loss: 0.2822 - val_accuracy: 0.9755\n",
      "Epoch 10/30\n",
      "48000/48000 [==============================] - 35s 727us/sample - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.2469 - val_accuracy: 0.9793\n",
      "Epoch 11/30\n",
      "48000/48000 [==============================] - 35s 734us/sample - loss: 0.0107 - accuracy: 0.9977 - val_loss: 0.3000 - val_accuracy: 0.9776\n",
      "Epoch 12/30\n",
      "48000/48000 [==============================] - 36s 740us/sample - loss: 0.0147 - accuracy: 0.9973 - val_loss: 0.2795 - val_accuracy: 0.9772\n",
      "Epoch 13/30\n",
      "48000/48000 [==============================] - 35s 733us/sample - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.2814 - val_accuracy: 0.9785\n",
      "Epoch 14/30\n",
      "48000/48000 [==============================] - 35s 719us/sample - loss: 0.0097 - accuracy: 0.9980 - val_loss: 0.2754 - val_accuracy: 0.9778\n",
      "Epoch 15/30\n",
      "48000/48000 [==============================] - 34s 709us/sample - loss: 0.0126 - accuracy: 0.9975 - val_loss: 0.2849 - val_accuracy: 0.9787\n",
      "Epoch 16/30\n",
      "48000/48000 [==============================] - 35s 737us/sample - loss: 0.0118 - accuracy: 0.9975 - val_loss: 0.3033 - val_accuracy: 0.9772\n",
      "Epoch 17/30\n",
      "48000/48000 [==============================] - 35s 724us/sample - loss: 0.0100 - accuracy: 0.9977 - val_loss: 0.3015 - val_accuracy: 0.9774\n",
      "Epoch 18/30\n",
      "48000/48000 [==============================] - 35s 731us/sample - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.3649 - val_accuracy: 0.9765\n",
      "Epoch 19/30\n",
      "48000/48000 [==============================] - 34s 699us/sample - loss: 0.0112 - accuracy: 0.9981 - val_loss: 0.3318 - val_accuracy: 0.9764\n",
      "Epoch 20/30\n",
      "48000/48000 [==============================] - 33s 696us/sample - loss: 0.0112 - accuracy: 0.9981 - val_loss: 0.3045 - val_accuracy: 0.9803\n",
      "Epoch 21/30\n",
      "48000/48000 [==============================] - 34s 698us/sample - loss: 0.0113 - accuracy: 0.9975 - val_loss: 0.3261 - val_accuracy: 0.9778\n",
      "Epoch 22/30\n",
      "48000/48000 [==============================] - 34s 702us/sample - loss: 0.0099 - accuracy: 0.9981 - val_loss: 0.3287 - val_accuracy: 0.9776\n",
      "Epoch 23/30\n",
      "48000/48000 [==============================] - 34s 708us/sample - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.2933 - val_accuracy: 0.9806\n",
      "Epoch 24/30\n",
      "48000/48000 [==============================] - 34s 711us/sample - loss: 0.0102 - accuracy: 0.9980 - val_loss: 0.3233 - val_accuracy: 0.9794\n",
      "Epoch 25/30\n",
      "48000/48000 [==============================] - 34s 705us/sample - loss: 0.0107 - accuracy: 0.9983 - val_loss: 0.3334 - val_accuracy: 0.9785\n",
      "Epoch 26/30\n",
      "48000/48000 [==============================] - 33s 692us/sample - loss: 0.0125 - accuracy: 0.9977 - val_loss: 0.3148 - val_accuracy: 0.9772\n",
      "Epoch 27/30\n",
      "48000/48000 [==============================] - 33s 691us/sample - loss: 0.0108 - accuracy: 0.9981 - val_loss: 0.3320 - val_accuracy: 0.9778\n",
      "Epoch 28/30\n",
      "48000/48000 [==============================] - 34s 702us/sample - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.3039 - val_accuracy: 0.9796\n",
      "Epoch 29/30\n",
      "48000/48000 [==============================] - 35s 732us/sample - loss: 0.0129 - accuracy: 0.9977 - val_loss: 0.4012 - val_accuracy: 0.9751\n",
      "Epoch 30/30\n",
      "48000/48000 [==============================] - 34s 708us/sample - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.3469 - val_accuracy: 0.9799\n"
     ]
    }
   ],
   "source": [
    "# モデルコンパイル\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 学習\n",
    "history = model.fit(X_train, y_train,\n",
    "                   batch_size=batch_size,\n",
    "                   epochs=num_epochs,\n",
    "                   verbose=1,\n",
    "                   validation_data=(X_val,y_val))\n",
    "\n",
    "# 推定結果(確率)\n",
    "y_pred_proba = model.predict(X_train)\n",
    "# 確率を一番高い値のインデックスに変換\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "specialized-cooperative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3251868995354289\n",
      "Test accuracy: 0.9794\n"
     ]
    }
   ],
   "source": [
    "# 指標値計算\n",
    "score = model.evaluate(X_test, y_test_one_hot, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3.7t2",
   "language": "python",
   "name": "p3.7t2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
